{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Data Cleaning dan Kombinasi CoreTax\n",
                "## Cleaning data scraping baru dan menggabungkan dengan data yang sudah ada\n",
                "\n",
                "**Data Input:**\n",
                "1. `CoreTax Scraper M Pajak 2025.csv` - Play Store reviews\n",
                "2. `Scraper Youtube CoreTax.csv` - YouTube comments\n",
                "3. `Hackathon Sentiment Analysis Combined.csv` - Data yang sudah ada sebelumnya\n",
                "\n",
                "**Output:**\n",
                "- Data bersih yang sudah digabungkan dengan format yang konsisten"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup dan Import Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import re\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "print(\"✓ Libraries imported successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Mount Google Drive dan Setup Path"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import drive\n",
                "import os\n",
                "\n",
                "print(\"Mounting Google Drive...\")\n",
                "drive.mount('/content/drive/')\n",
                "print(\"✓ Google Drive mounted!\")\n",
                "\n",
                "# Set data path\n",
                "DATA_PATH = '/content/drive/MyDrive/Hackathon/data/'\n",
                "\n",
                "print(f\"Data path: {DATA_PATH}\")\n",
                "\n",
                "# Cek apakah folder ada\n",
                "if os.path.exists(DATA_PATH):\n",
                "    print(\"✓ Data folder found!\")\n",
                "    print(f\"\\nFiles in data folder:\")\n",
                "    for file in os.listdir(DATA_PATH):\n",
                "        print(f\"  - {file}\")\n",
                "else:\n",
                "    print(\"⚠️ Data folder not found! Please check the path.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Fungsi Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def clean_text(text):\n",
                "    \"\"\"\n",
                "    Fungsi untuk membersihkan teks\n",
                "    \"\"\"\n",
                "    if pd.isna(text):\n",
                "        return \"\"\n",
                "    \n",
                "    text = str(text)\n",
                "    \n",
                "    # Lowercase\n",
                "    text = text.lower()\n",
                "    \n",
                "    # Remove URLs\n",
                "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
                "    \n",
                "    # Remove mentions (@username)\n",
                "    text = re.sub(r'@\\w+', '', text)\n",
                "    \n",
                "    # Remove hashtags tapi simpan kata-katanya\n",
                "    text = re.sub(r'#(\\w+)', r'\\1', text)\n",
                "    \n",
                "    # Remove email\n",
                "    text = re.sub(r'\\S+@\\S+', '', text)\n",
                "    \n",
                "    # Remove extra whitespace\n",
                "    text = re.sub(r'\\s+', ' ', text).strip()\n",
                "    \n",
                "    return text\n",
                "\n",
                "print(\"✓ Fungsi preprocessing ready!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Load Data yang Sudah Ada (Hackathon Sentiment Analysis Combined)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 80)\n",
                "print(\"LOADING DATA YANG SUDAH ADA\")\n",
                "print(\"=\" * 80)\n",
                "\n",
                "try:\n",
                "    FILE_NAME = 'Hackathon Sentiment Analysis Combined.csv'\n",
                "    df_existing = pd.read_csv(DATA_PATH + FILE_NAME, encoding='utf-8')\n",
                "    \n",
                "    print(f\"✓ Data existing loaded: {len(df_existing)} baris\")\n",
                "    print(f\"Kolom: {df_existing.columns.tolist()}\")\n",
                "    print(f\"\\nPreview data:\")\n",
                "    display(df_existing.head())\n",
                "    \n",
                "    print(f\"\\nDistribusi source:\")\n",
                "    print(df_existing['source'].value_counts())\n",
                "    \n",
                "    if 'sentiment' in df_existing.columns:\n",
                "        print(f\"\\nDistribusi sentiment:\")\n",
                "        print(df_existing['sentiment'].value_counts())\n",
                "    \n",
                "except Exception as e:\n",
                "    print(f\"⚠️ Error loading existing data: {e}\")\n",
                "    df_existing = pd.DataFrame()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Load dan Clean Data Play Store (M Pajak)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 80)\n",
                "print(\"CLEANING DATA: CoreTax Scraper M Pajak 2025.csv\")\n",
                "print(\"=\" * 80)\n",
                "\n",
                "try:\n",
                "    # Load data Play Store\n",
                "    df_playstore = pd.read_csv(DATA_PATH + 'CoreTax Scraper M Pajak 2025.csv', encoding='utf-8')\n",
                "    \n",
                "    print(f\"✓ Data Play Store loaded: {len(df_playstore)} baris\")\n",
                "    print(f\"Kolom: {df_playstore.columns.tolist()}\")\n",
                "    print(f\"\\nPreview data:\")\n",
                "    display(df_playstore.head())\n",
                "    \n",
                "    # Rename kolom agar sesuai format\n",
                "    # rating, at, content, source -> date, text, source\n",
                "    df_playstore_clean = pd.DataFrame({\n",
                "        'text': df_playstore['content'],\n",
                "        'source': 'play_store'\n",
                "    })\n",
                "    \n",
                "    # Tambahkan kolom date jika ada\n",
                "    if 'at' in df_playstore.columns:\n",
                "        df_playstore_clean['date'] = df_playstore['at']\n",
                "    \n",
                "    # Tambahkan kolom rating untuk referensi\n",
                "    if 'rating' in df_playstore.columns:\n",
                "        df_playstore_clean['rating'] = df_playstore['rating']\n",
                "    \n",
                "    # Clean text\n",
                "    print(\"\\nCleaning text...\")\n",
                "    df_playstore_clean['cleaned_text'] = df_playstore_clean['text'].apply(clean_text)\n",
                "    \n",
                "    # Filter data yang kosong setelah cleaning\n",
                "    df_playstore_clean = df_playstore_clean[\n",
                "        df_playstore_clean['cleaned_text'].str.len() > 0\n",
                "    ].reset_index(drop=True)\n",
                "    \n",
                "    print(f\"\\n✓ Data Play Store setelah cleaning: {len(df_playstore_clean)} baris\")\n",
                "    \n",
                "    if 'rating' in df_playstore_clean.columns:\n",
                "        print(f\"\\nDistribusi rating:\")\n",
                "        print(df_playstore_clean['rating'].value_counts().sort_index())\n",
                "    \n",
                "    print(f\"\\nPreview data bersih:\")\n",
                "    display(df_playstore_clean.head())\n",
                "    \n",
                "except Exception as e:\n",
                "    print(f\"⚠️ Error loading Play Store data: {e}\")\n",
                "    df_playstore_clean = pd.DataFrame()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Load dan Clean Data YouTube"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 80)\n",
                "print(\"CLEANING DATA: Scraper Youtube CoreTax.csv\")\n",
                "print(\"=\" * 80)\n",
                "\n",
                "try:\n",
                "    # Load data YouTube\n",
                "    df_youtube = pd.read_csv(DATA_PATH + 'Scraper Youtube CoreTax.csv', encoding='utf-8')\n",
                "    \n",
                "    print(f\"✓ Data YouTube loaded: {len(df_youtube)} baris\")\n",
                "    print(f\"Kolom: {df_youtube.columns.tolist()}\")\n",
                "    print(f\"\\nPreview data:\")\n",
                "    display(df_youtube.head())\n",
                "    \n",
                "    # Rename kolom agar sesuai format\n",
                "    df_youtube_clean = pd.DataFrame({\n",
                "        'text': df_youtube['text'],\n",
                "        'source': 'youtube'\n",
                "    })\n",
                "    \n",
                "    # Tambahkan kolom date jika ada\n",
                "    if 'date' in df_youtube.columns:\n",
                "        df_youtube_clean['date'] = df_youtube['date']\n",
                "    \n",
                "    # Clean text\n",
                "    print(\"\\nCleaning text...\")\n",
                "    df_youtube_clean['cleaned_text'] = df_youtube_clean['text'].apply(clean_text)\n",
                "    \n",
                "    # Filter data yang kosong setelah cleaning\n",
                "    df_youtube_clean = df_youtube_clean[\n",
                "        df_youtube_clean['cleaned_text'].str.len() > 0\n",
                "    ].reset_index(drop=True)\n",
                "    \n",
                "    print(f\"\\n✓ Data YouTube setelah cleaning: {len(df_youtube_clean)} baris\")\n",
                "    print(f\"\\nPreview data bersih:\")\n",
                "    display(df_youtube_clean.head())\n",
                "    \n",
                "except Exception as e:\n",
                "    print(f\"⚠️ Error loading YouTube data: {e}\")\n",
                "    df_youtube_clean = pd.DataFrame()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Kombinasi Semua Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 80)\n",
                "print(\"KOMBINASI SEMUA DATA\")\n",
                "print(\"=\" * 80)\n",
                "\n",
                "# List untuk menyimpan dataframe yang akan digabungkan\n",
                "dfs_to_combine = []\n",
                "\n",
                "# Tentukan kolom yang akan digunakan\n",
                "# Kolom minimal: text, cleaned_text, source\n",
                "base_columns = ['text', 'cleaned_text', 'source']\n",
                "\n",
                "# Proses data existing\n",
                "if len(df_existing) > 0:\n",
                "    df_existing_processed = df_existing.copy()\n",
                "    \n",
                "    # Pastikan ada kolom cleaned_text\n",
                "    if 'cleaned_text' not in df_existing_processed.columns:\n",
                "        print(\"Membuat cleaned_text untuk data existing...\")\n",
                "        df_existing_processed['cleaned_text'] = df_existing_processed['text'].apply(clean_text)\n",
                "    \n",
                "    # Jika tidak ada kolom text, gunakan cleaned_text sebagai text\n",
                "    if 'text' not in df_existing_processed.columns and 'cleaned_text' in df_existing_processed.columns:\n",
                "        df_existing_processed['text'] = df_existing_processed['cleaned_text']\n",
                "    \n",
                "    # Pilih kolom yang ada\n",
                "    cols_to_keep = [col for col in df_existing_processed.columns if col in base_columns or col in ['sentiment', 'sentiment_score', 'date']]\n",
                "    df_existing_final = df_existing_processed[cols_to_keep].copy()\n",
                "    dfs_to_combine.append(df_existing_final)\n",
                "    print(f\"✓ Data existing: {len(df_existing_final)} baris\")\n",
                "\n",
                "# Proses data Play Store\n",
                "if len(df_playstore_clean) > 0:\n",
                "    cols_to_keep = [col for col in df_playstore_clean.columns if col in base_columns or col in ['date', 'rating']]\n",
                "    df_playstore_final = df_playstore_clean[cols_to_keep].copy()\n",
                "    dfs_to_combine.append(df_playstore_final)\n",
                "    print(f\"✓ Data Play Store: {len(df_playstore_final)} baris\")\n",
                "\n",
                "# Proses data YouTube\n",
                "if len(df_youtube_clean) > 0:\n",
                "    cols_to_keep = [col for col in df_youtube_clean.columns if col in base_columns or col in ['date']]\n",
                "    df_youtube_final = df_youtube_clean[cols_to_keep].copy()\n",
                "    dfs_to_combine.append(df_youtube_final)\n",
                "    print(f\"✓ Data YouTube: {len(df_youtube_final)} baris\")\n",
                "\n",
                "# Gabungkan semua data\n",
                "if len(dfs_to_combine) > 0:\n",
                "    df_combined = pd.concat(dfs_to_combine, ignore_index=True)\n",
                "    \n",
                "    # Shuffle data\n",
                "    df_combined = df_combined.sample(frac=1, random_state=42).reset_index(drop=True)\n",
                "    \n",
                "    print(f\"\\n✓ Data berhasil digabungkan!\")\n",
                "    print(f\"Total data: {len(df_combined)} baris\")\n",
                "    \n",
                "    print(f\"\\nDistribusi per source:\")\n",
                "    print(df_combined['source'].value_counts())\n",
                "    \n",
                "    if 'sentiment' in df_combined.columns:\n",
                "        print(f\"\\nDistribusi sentiment:\")\n",
                "        print(df_combined['sentiment'].value_counts())\n",
                "    \n",
                "    print(f\"\\nPreview data gabungan:\")\n",
                "    display(df_combined.head(10))\n",
                "    \n",
                "else:\n",
                "    print(\"⚠️ Tidak ada data untuk digabungkan\")\n",
                "    df_combined = pd.DataFrame()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Statistik Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 80)\n",
                "print(\"STATISTIK DATA\")\n",
                "print(\"=\" * 80)\n",
                "\n",
                "if len(df_combined) > 0:\n",
                "    print(f\"\\nTotal data: {len(df_combined)} baris\")\n",
                "    print(f\"\\nKolom yang tersedia:\")\n",
                "    print(df_combined.columns.tolist())\n",
                "    \n",
                "    print(f\"\\nInfo data:\")\n",
                "    df_combined.info()\n",
                "    \n",
                "    print(f\"\\nStatistik panjang text:\")\n",
                "    df_combined['text_length'] = df_combined['text'].str.len()\n",
                "    df_combined['cleaned_text_length'] = df_combined['cleaned_text'].str.len()\n",
                "    \n",
                "    print(df_combined[['text_length', 'cleaned_text_length']].describe())\n",
                "    \n",
                "    # Hapus kolom temporary\n",
                "    df_combined = df_combined.drop(['text_length', 'cleaned_text_length'], axis=1)\n",
                "else:\n",
                "    print(\"⚠️ Tidak ada data untuk ditampilkan\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Export Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 80)\n",
                "print(\"EXPORT DATA\")\n",
                "print(\"=\" * 80)\n",
                "\n",
                "if len(df_combined) > 0:\n",
                "    # Export combined file\n",
                "    output_filename = DATA_PATH + 'CoreTax_All_Data_Combined_Clean.csv'\n",
                "    df_combined.to_csv(output_filename, index=False)\n",
                "    print(f\"✓ Data gabungan exported to: {output_filename}\")\n",
                "    \n",
                "    # Export individual files jika diperlukan\n",
                "    if len(df_playstore_clean) > 0:\n",
                "        df_playstore_clean.to_csv(DATA_PATH + 'cleaned_playstore_coretax.csv', index=False)\n",
                "        print(f\"✓ Play Store data exported to: {DATA_PATH}cleaned_playstore_coretax.csv\")\n",
                "    \n",
                "    if len(df_youtube_clean) > 0:\n",
                "        df_youtube_clean.to_csv(DATA_PATH + 'cleaned_youtube_coretax.csv', index=False)\n",
                "        print(f\"✓ YouTube data exported to: {DATA_PATH}cleaned_youtube_coretax.csv\")\n",
                "    \n",
                "    print(f\"\\n✓ Semua file berhasil di-export!\")\n",
                "    \n",
                "    # Download file (untuk Google Colab)\n",
                "    try:\n",
                "        from google.colab import files\n",
                "        print(f\"\\nDownloading file...\")\n",
                "        files.download(output_filename)\n",
                "        print(f\"✓ File downloaded!\")\n",
                "    except:\n",
                "        print(f\"\\n(File tersimpan di Google Drive: {output_filename})\")\n",
                "else:\n",
                "    print(\"⚠️ Tidak ada data untuk di-export\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 80)\n",
                "print(\"SUMMARY\")\n",
                "print(\"=\" * 80)\n",
                "\n",
                "print(f\"\\n✓ Data cleaning dan kombinasi selesai!\")\n",
                "print(f\"\\nFile output (tersimpan di Google Drive):\")\n",
                "print(f\"  1. {DATA_PATH}CoreTax_All_Data_Combined_Clean.csv (MAIN FILE)\")\n",
                "print(f\"  2. {DATA_PATH}cleaned_playstore_coretax.csv\")\n",
                "print(f\"  3. {DATA_PATH}cleaned_youtube_coretax.csv\")\n",
                "\n",
                "if len(df_combined) > 0:\n",
                "    print(f\"\\nTotal data bersih: {len(df_combined):,} baris\")\n",
                "    print(f\"\\nBreakdown per source:\")\n",
                "    for source, count in df_combined['source'].value_counts().items():\n",
                "        percentage = (count / len(df_combined)) * 100\n",
                "        print(f\"  - {source}: {count:,} baris ({percentage:.2f}%)\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}